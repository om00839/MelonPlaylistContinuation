{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26569,
     "status": "ok",
     "timestamp": 1595059933155,
     "user": {
      "displayName": "Jaeho Jang",
      "photoUrl": "",
      "userId": "06755739837375243442"
     },
     "user_tz": -540
    },
    "id": "11Fx89Vb8u5W",
    "outputId": "0844db85-90a9-4893-aaa4-46a75d6d5309"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28076,
     "status": "ok",
     "timestamp": 1595059934686,
     "user": {
      "displayName": "Jaeho Jang",
      "photoUrl": "",
      "userId": "06755739837375243442"
     },
     "user_tz": -540
    },
    "id": "72zMxt0ogBJx"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d9f1f4806db8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Protocol buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_def_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/core/framework/graph_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0m_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdescriptor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_descriptor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreflection\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_reflection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/google/protobuf/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pkg_resources'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeclare_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0m__path__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pkgutil'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__path__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pkg_resources.extern.packaging.version'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pkg_resources.extern.packaging.specifiers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pkg_resources.extern.packaging.requirements'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pkg_resources.extern.packaging.markers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pkg_resources.py2_warn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pkg_resources/_vendor/packaging/requirements.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyparsing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstringStart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstringEnd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginalTextFor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParseException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyparsing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mZeroOrMore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRegex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCombine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyparsing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mL\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_backward_compatible\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pkg_resources/extern/__init__.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(self, fullname)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mextant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mextant\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfullname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[0;34m(data, name, bytecode_path, source_path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from itertools import chain\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6GqEDGgjkwwn"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28063,
     "status": "ok",
     "timestamp": 1595059934687,
     "user": {
      "displayName": "Jaeho Jang",
      "photoUrl": "",
      "userId": "06755739837375243442"
     },
     "user_tz": -540
    },
    "id": "axSrqqMHo_Xm"
   },
   "outputs": [],
   "source": [
    "class MPCDataset:\n",
    "    def __init__(self, data_dir, info_dir='./info/', **kwargs):\n",
    "        \n",
    "        self.data_dir = data_dir if data_dir[-1] == '/' else data_dir + '/'\n",
    "        self.info_dir = info_dir if info_dir[-1] == '/' else info_dir + '/'\n",
    "        \n",
    "        self.train_plylst_list = None\n",
    "        self.val_plylst_list = None\n",
    "        self.test_plylst_list = None\n",
    "        \n",
    "        self.song_tag_d2v = None\n",
    "        self.tag_song_d2v = None\n",
    "        \n",
    "        self.tag_maxlen = None\n",
    "        self.n_tags = None\n",
    "        self.idx2tag = None\n",
    "        self.tag2idx = None\n",
    "        \n",
    "        self.song_maxlen = None\n",
    "        self.n_songs = None\n",
    "        self.idx2song = None\n",
    "        self.song2idx = None\n",
    "        \n",
    "        self.song_vectors = None\n",
    "        self.tag_vectors = None\n",
    "        \n",
    "        self.song_window=100\n",
    "        self.tag_window=5\n",
    "        self.min_count=2\n",
    "        self.negative=5\n",
    "        self.worker=4\n",
    "        self.vector_size=64\n",
    "        for k,v in kwargs.items():\n",
    "            if k == 'song_window':\n",
    "                song_window=v\n",
    "            if k == 'tag_window':\n",
    "                tag_window=v\n",
    "            if k == 'min_count':\n",
    "                min_count=v\n",
    "            if k == 'negative':\n",
    "                negative=v\n",
    "            if k == 'worker':\n",
    "                worker=v\n",
    "            if k == 'vector_size':\n",
    "                vector_size=v\n",
    "        \n",
    "        if not os.path.isdir(self.info_dir):\n",
    "            os.mkdir(self.info_dir)\n",
    "\n",
    "        self.train_plylst_list = self.load_json(\n",
    "            os.path.join(self.data_dir, 'train.json'))\n",
    "        self.val_plylst_list = self.load_json(\n",
    "            os.path.join(self.data_dir, 'val.json'))\n",
    "        self.test_plylst_list = self.load_json(\n",
    "            os.path.join(self.data_dir, 'test.json'))\n",
    "        \n",
    "        # load song_tag_d2v, tag_song_d2v\n",
    "        self.song_tag_d2v, self.tag_song_d2v = self.get_d2v_models()    \n",
    "        \n",
    "        self.idx2song = ['<pad>', '<unk>'] + self.song_tag_d2v.wv.index2word\n",
    "        self.song2idx = {song:idx for idx, song in enumerate(self.idx2song)}\n",
    "        \n",
    "        self.idx2tag = ['<pad>', '<unk>'] + self.tag_song_d2v.wv.index2word\n",
    "        self.tag2idx = {tag:idx for idx, tag in enumerate(self.idx2tag)}\n",
    "        \n",
    "        self.song_maxlen, self.tag_maxlen = self.get_maxlen()\n",
    "        self.n_songs = len(self.idx2song)\n",
    "        self.n_tags = len(self.idx2tag)\n",
    "        \n",
    "        song_vectors_path = self.info_dir + 'song_vectors.npy'\n",
    "        tag_vectors_path = self.info_dir + 'tag_vectors.npy'\n",
    "        if not (os.path.isfile(song_vectors_path) and os.path.isfile(tag_vectors_path)):\n",
    "            self.song_vectors = np.concatenate([np.zeros((2, self.vector_size)), \n",
    "                                  self.tag_song_d2v.wv.vectors], axis=0)\n",
    "            self.tag_vectors = np.concatenate([np.zeros((2, self.vector_size)), \n",
    "                                  self.song_tag_d2v.wv.vectors], axis=0)\n",
    "            \n",
    "            np.save(song_vectors_path, self.song_vectors)\n",
    "            np.save(tag_vectors_path, self.tag_vectors)\n",
    "            \n",
    "        elif os.path.isfile(song_vectors_path) and os.path.isfile(tag_vectors_path):\n",
    "            self.song_vectors = np.load(song_vectors_path)\n",
    "            self.tag_vectors = np.load(tag_vectors_path)\n",
    "\n",
    "    def load_json(self, path):\n",
    "        return json.load(open(path, 'r'))\n",
    "    \n",
    "    def get_d2v_models(self):\n",
    "        song_tag_d2v_path = self.info_dir + 'song_tag_d2v.model'\n",
    "        tag_song_d2v_path = self.info_dir + 'tag_song_d2v.model'\n",
    "        \n",
    "        song_tag_d2v = None\n",
    "        tag_song_d2v = None\n",
    "        if not(os.path.isfile(song_tag_d2v_path) and os.path.isfile(tag_song_d2v_path)):\n",
    "            song_tag_doc_list = list()\n",
    "            tag_song_doc_list = list()\n",
    "            for plylst in chain(self.train_plylst_list, \n",
    "                                self.val_plylst_list, \n",
    "                                self.test_plylst_list):\n",
    "                songs = list()\n",
    "                for song in plylst['songs']:\n",
    "                    songs.append(str(song))\n",
    "                    \n",
    "                tags = list()\n",
    "                for tag in plylst['tags']:\n",
    "                    tags.append(str(tag))\n",
    "                    \n",
    "                song_tag_doc_list.append(TaggedDocument(songs, tags))\n",
    "                tag_song_doc_list.append(TaggedDocument(tags, songs))\n",
    "\n",
    "            song_tag_d2v = Doc2Vec(song_tag_doc_list, window=self.song_window, \n",
    "                                   min_count=self.min_count, negative=self.negative, \n",
    "                                   worker=self.worker, vector_size=self.vector_size)\n",
    "            tag_song_d2v = Doc2Vec(tag_song_doc_list, window=self.tag_window, \n",
    "                                   min_count=self.min_count, negative=self.negative, \n",
    "                                   worker=self.worker, vector_size=self.vector_size)\n",
    "            \n",
    "            song_tag_d2v.save(song_tag_d2v_path)\n",
    "            tag_song_d2v.save(tag_song_d2v_path)\n",
    "\n",
    "            \n",
    "        elif os.path.isfile(song_tag_d2v_path) and os.path.isfile(tag_song_d2v_path):\n",
    "            song_tag_d2v = Doc2Vec.load(song_tag_d2v_path)\n",
    "            tag_song_d2v = Doc2Vec.load(tag_song_d2v_path)\n",
    "        \n",
    "        return song_tag_d2v, tag_song_d2v\n",
    "    \n",
    "    def get_maxlen(self):\n",
    "        song_maxlen = -1\n",
    "        tag_maxlen = -1\n",
    "        for plylst in chain(self.train_plylst_list, \n",
    "                            self.val_plylst_list, \n",
    "                            self.test_plylst_list):\n",
    "            song_maxlen = max(song_maxlen, len(plylst['songs']))\n",
    "            tag_maxlen = max(tag_maxlen, len(plylst['tags']))\n",
    "            \n",
    "        return song_maxlen, tag_maxlen\n",
    "    \n",
    "    def generate_input(self, mode, batch_size):\n",
    "        def _encode(plylst, feature):\n",
    "            \n",
    "            if feature == 'tag':\n",
    "                feat_idxs = list()\n",
    "                for tag in plylst['tags']:\n",
    "                    if self.tag2idx.setdefault(str(tag), False):\n",
    "                        feat_idxs.append(self.tag2idx[str(tag)])\n",
    "                    else:\n",
    "                        feat_idxs.append(self.tag2idx['<unk>'])\n",
    "                feat_maxlen = self.tag_maxlen\n",
    "                n_feats = self.n_tags\n",
    "            else:\n",
    "                feat_idxs = list()\n",
    "                for song in plylst['songs']:\n",
    "                    if self.song2idx.setdefault(str(song), False):\n",
    "                        feat_idxs.append(self.song2idx[str(song)])\n",
    "                    else:\n",
    "                        feat_idxs.append(self.song2idx['<unk>'])\n",
    "                feat_maxlen = self.song_maxlen\n",
    "                n_feats = self.n_songs\n",
    "\n",
    "            feat_in = np.zeros((feat_maxlen,), dtype=np.int32)\n",
    "            for i, idx in enumerate(feat_idxs):\n",
    "                feat_in[i] = idx\n",
    "            feat_out = np.zeros((n_feats,), dtype=np.int32)\n",
    "            feat_out[feat_in[:n_feats]] = 1\n",
    "            \n",
    "            return feat_in, feat_out\n",
    "        \n",
    "        if mode == 'train':\n",
    "            plylst_list = self.train_plylst_list\n",
    "        elif mode == 'val':\n",
    "            plylst_list = self.val_plylst_list\n",
    "        elif mode == 'test':\n",
    "            plylst_list = self.test_plylst_list\n",
    "        else:\n",
    "            raise(ValueError)\n",
    "            \n",
    "        song_in_list = list()\n",
    "        tag_in_list = list()\n",
    "        song_out_list = list()\n",
    "        tag_out_list = list()\n",
    "        for i, plylst in enumerate(plylst_list, 1):\n",
    "            song_in, song_out = _encode(plylst, 'song')\n",
    "            tag_in, tag_out = _encode(plylst, 'tag')\n",
    "            song_in_list.append(song_in)\n",
    "            tag_in_list.append(tag_in)\n",
    "            song_out_list.append(song_out)\n",
    "            tag_out_list.append(tag_out)\n",
    "            \n",
    "            if i%batch_size == 0:\n",
    "                song_in = np.stack(song_in_list, axis=0)\n",
    "                tag_in = np.stack(tag_in_list, axis=0)\n",
    "                song_in_list = list()\n",
    "                tag_in_list = list()\n",
    "                \n",
    "                song_out = np.stack(song_out_list, axis=0)\n",
    "                tag_out = np.stack(tag_out_list, axis=0)\n",
    "                song_out_list = list()\n",
    "                tag_out_list = list()\n",
    "                \n",
    "                yield (song_in, tag_in), (song_out, tag_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbm2DsfUmGUs"
   },
   "source": [
    "## Configuraiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28050,
     "status": "ok",
     "timestamp": 1595059934687,
     "user": {
      "displayName": "Jaeho Jang",
      "photoUrl": "",
      "userId": "06755739837375243442"
     },
     "user_tz": -540
    },
    "id": "87DCDXK_JJ1e"
   },
   "outputs": [],
   "source": [
    "class Configuration:\n",
    "    def __init__(self, **kwargs):\n",
    "        # model configuration\n",
    "        self.song_hidden_dim = 64\n",
    "        self.tag_hidden_dim = 64\n",
    "        self.song_maxlen = None\n",
    "        self.tag_maxlen = None\n",
    "        self.n_songs = None\n",
    "        self.n_tags = None\n",
    "        \n",
    "        # train configuration\n",
    "        self.batch_size = 32\n",
    "        self.lr = 1e-4\n",
    "        \n",
    "        for k, v in kwargs.items():\n",
    "            if k == 'song_hidden_dim':\n",
    "                self.song_hidden_dim = v\n",
    "            elif k == 'tag_hidden_dim':\n",
    "                self.tag_hidden_dim = v\n",
    "            elif k == 'song_maxlen':\n",
    "                self.song_maxlen = v\n",
    "            elif k == 'tag_maxlen':\n",
    "                self.tag_maxlen = v\n",
    "            elif k == 'n_songs':\n",
    "                self.n_songs = v\n",
    "            elif k == 'n_tags':\n",
    "                self.n_tags = v\n",
    "            elif k == 'batch_size':\n",
    "                self.batch_size = v\n",
    "            elif k == 'lr':\n",
    "                self.lr = v\n",
    "            elif k == 'epochs':\n",
    "                self.epochs = v\n",
    "            else:\n",
    "                raise(ValueError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8J62HICCJJ1g"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28034,
     "status": "ok",
     "timestamp": 1595059934688,
     "user": {
      "displayName": "Jaeho Jang",
      "photoUrl": "",
      "userId": "06755739837375243442"
     },
     "user_tz": -540
    },
    "id": "j4_emKeQjbLh"
   },
   "outputs": [],
   "source": [
    "class EmbMLP(keras.Model):\n",
    "    def __init__(self, config, song_vectors, tag_vectors):\n",
    "        super(EmbMLP, self).__init__()\n",
    "        self.config = config\n",
    "#         self.song_lookup_table = tf.constant(song_vectors)\n",
    "        self.song_embedding = layers.Embedding(self.config.n_songs,\n",
    "                                          self.config.song_hidden_dim, \n",
    "                                          embeddings_initializer=tf.keras.initializers.Constant(song_vectors))\n",
    "#         self.tag_lookup_table = tf.constant(tag_vectors)\n",
    "        self.tag_embedding = layers.Embedding(self.config.n_tags,\n",
    "                                          self.config.tag_hidden_dim, \n",
    "                                          embeddings_initializer=tf.keras.initializers.Constant(tag_vectors))\n",
    "        \n",
    "        self.linear = layers.Dense(self.config.n_songs + self.config.n_tags, \n",
    "                                   input_shape=(self.config.song_hidden_dim + self.config.tag_hidden_dim,))\n",
    "\n",
    "    def call(self, input):\n",
    "        song_in, tag_in = input\n",
    "        song_embedded = self.song_embedding(song_in)\n",
    "        tag_embedded = self.tag_embedding(tag_in)\n",
    "#         song_embedded = tf.nn.embedding_lookup(self.song_lookup_table, song_in)\n",
    "#         tag_embedded = tf.nn.embedding_lookup(self.tag_lookup_table, tag_in)\n",
    "        concated = tf.nn.relu(tf.concat([song_embedded, tag_embedded], axis=-1))\n",
    "        logits_concated = self.linear(concated)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hXh4KySIJJ1k"
   },
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28020,
     "status": "ok",
     "timestamp": 1595059934689,
     "user": {
      "displayName": "Jaeho Jang",
      "photoUrl": "",
      "userId": "06755739837375243442"
     },
     "user_tz": -540
    },
    "id": "p3hVTWVQshg2"
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, config, dataset):\n",
    "        self.config = config\n",
    "        self.model = EmbMLP(self.config, dataset.song_vectors, dataset.tag_vectors)\n",
    "        self.optimizer = keras.optimizers.Adam(config.lr)\n",
    "        \n",
    "        for epoch in range(1, config.epochs):\n",
    "            # train \n",
    "            generator = iter(dataset.generate_input('train', config.batch_size))\n",
    "            N = len(dataset.train_plylst_list)\n",
    "            steps_per_epoch = (N // config.batch_size) + 1\n",
    "            loss_list = list()\n",
    "            for step in range(steps_per_epoch):\n",
    "                input, label = next(generator)\n",
    "                label = tf.concat(label, axis=-1)\n",
    "                loss = self.train_batches(input, label)\n",
    "                loss_list.append(loss.numpy())\n",
    "                vars_ = self.model.trainable_variables\n",
    "                grads = tape.gradient(loss, vars_)\n",
    "                self.optimizer.apply_gradients(zip(grads, vars_))\n",
    "                \n",
    "            print(f\"epoch {epoch}\\t|\\tavg. loss: {np.mean(loss_list)}\")\n",
    "                \n",
    "            # evaluate\n",
    "            generator = iter(dataset.generate_input('val', config.batch_size))\n",
    "            N = len(dataset.val_plylst_list)\n",
    "            steps_per_epoch = (N // config.batch_size) + 1\n",
    "            song_ndcg_list = list()\n",
    "            tag_ndcg_list = list()\n",
    "            for step in range(steps_per_epoch):\n",
    "                input, (song_label, tag_label) = next(generator)\n",
    "                logits = self.eval_batches(input)\n",
    "                song_logits, tag_logits = tf.split(logits, (config.n_songs, config.n_tags), -1)\n",
    "                song_mask = -song_label+1\n",
    "                tag_mask = -tag_label+1\n",
    "                song_masked_logits = song_mask * song_logits\n",
    "                tag_masked_logits = tag_mask * tag_logits\n",
    "                songs_top100 = tf.math.top_k(song_masked_logits, k=100)\n",
    "                tags_top5 = tf.math.top_k(tag_masked_logits, k=5)\n",
    "                \n",
    "                for i in range(songs_top100.shape[0]):\n",
    "                    song_nDCG = self._ndcg(songs_top100[i,:].tolist())\n",
    "                    song_ndcg_list.append(song_nDCG)\n",
    "                    tag_nDCG = self._ndcg(tags_top5[i,:].tolist())\n",
    "                    tag_ndcg_list.append(tag_nDCG)\n",
    "                    \n",
    "            score = 0.85 * np.mean(song_ndcg_list) + 0.15 * np.mean(tag_ndcg_list)\n",
    "            print(f\"epoch {epoch}\\t|\\tscore: {score}\")\n",
    "            \n",
    "    def train_batches(self, input, label):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.model(input)\n",
    "            label = tf.con\n",
    "            loss = tf.nn.softmax_cross_entropy_with_logits(label, logits)\n",
    "        return loss\n",
    "            \n",
    "    def eval_batches(self, input):\n",
    "        logits = self.model(input)\n",
    "        \n",
    "        return song_logits, tag_logits\n",
    "    \n",
    "    def _ndcg(self, gt, rec):\n",
    "        dcg = 0.0\n",
    "        for i, r in enumerate(rec):\n",
    "            if r in gt:\n",
    "                dcg += 1.0 / np.log(i + 2)\n",
    "        return dcg / self._idcgs[len(gt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6MApZ2gJJ1n"
   },
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "dataset = MPCDataset('/content/drive/My Drive/MelonPlaylistContinuation/data/')\n",
    "config = Configuration(song_maxlen = dataset.song_maxlen, \n",
    "                       tag_maxlen=dataset.tag_maxlen,\n",
    "                       n_songs=dataset.n_songs,\n",
    "                       n_tags=dataset.n_tags, \n",
    "                       batch_size=4, \n",
    "                       epochs=30)\n",
    "trainer = Trainer(config, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49508,
     "status": "aborted",
     "timestamp": 1595059956209,
     "user": {
      "displayName": "Jaeho Jang",
      "photoUrl": "",
      "userId": "06755739837375243442"
     },
     "user_tz": -540
    },
    "id": "2b4UdXhdJJ1r"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MelonPlaylistContinuation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
