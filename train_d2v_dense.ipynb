{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_d2v_dense.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1EW6X2qMhqJET6VGGF3asSVpbvKAau81U","authorship_tag":"ABX9TyMiWM9aKpuLU/aREgGljydS"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Lllmz2oizr7H","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595426130882,"user_tz":-540,"elapsed":1203,"user":{"displayName":"Jaeho Jang","photoUrl":"","userId":"06755739837375243442"}}},"source":["class MPCDataset:\n","    def __init__(self, data_dir, info_dir='./info/', **kwargs):\n","        \n","        self.data_dir = data_dir if data_dir[-1] == '/' else data_dir + '/'\n","        self.info_dir = info_dir if info_dir[-1] == '/' else info_dir + '/'\n","        \n","        self.train_plylst_list = None\n","        self.val_plylst_list = None\n","        self.test_plylst_list = None\n","        \n","        self.song_tag_d2v = None\n","        self.tag_song_d2v = None\n","        \n","        self.tag_maxlen = None\n","        self.n_tags = None\n","        self.idx2tag = None\n","        self.tag2idx = None\n","        \n","        self.song_maxlen = None\n","        self.n_songs = None\n","        self.idx2song = None\n","        self.song2idx = None\n","        \n","        self.song_vectors = None\n","        self.tag_vectors = None\n","        \n","        self.song_window=100\n","        self.tag_window=5\n","        self.min_count=2\n","        self.negative=5\n","        self.worker=4\n","        self.vector_size=256\n","        for k,v in kwargs.items():\n","            if k == 'song_window':\n","                song_window=v\n","            if k == 'tag_window':\n","                tag_window=v\n","            if k == 'min_count':\n","                min_count=v\n","            if k == 'negative':\n","                negative=v\n","            if k == 'worker':\n","                worker=v\n","            if k == 'vector_size':\n","                vector_size=v\n","        \n","        if not os.path.isdir(self.info_dir):\n","            os.mkdir(self.info_dir)\n","\n","        self.train_plylst_list = self.load_json(\n","            os.path.join(self.data_dir, 'train.json'))\n","        self.val_plylst_list = self.load_json(\n","            os.path.join(self.data_dir, 'val.json'))\n","        self.test_plylst_list = self.load_json(\n","            os.path.join(self.data_dir, 'test.json'))\n","        \n","        # load song_tag_d2v, tag_song_d2v\n","        self.song_tag_d2v, self.tag_song_d2v = self.get_d2v_models()    \n","        \n","        self.idx2song = ['<pad>', '<unk>'] + self.song_tag_d2v.wv.index2word\n","        self.song2idx = {song:idx for idx, song in enumerate(self.idx2song)}\n","        \n","        self.idx2tag = ['<pad>', '<unk>'] + self.tag_song_d2v.wv.index2word\n","        self.tag2idx = {tag:idx for idx, tag in enumerate(self.idx2tag)}\n","        \n","        self.song_maxlen, self.tag_maxlen = self.get_maxlen()\n","        self.n_songs = len(self.idx2song)\n","        self.n_tags = len(self.idx2tag)\n","        \n","        song_vectors_path = self.info_dir + 'song_vectors.npy'\n","        tag_vectors_path = self.info_dir + 'tag_vectors.npy'\n","        if not (os.path.isfile(song_vectors_path) and os.path.isfile(tag_vectors_path)):\n","            self.song_vectors = np.concatenate([np.zeros((2, self.vector_size)), \n","                                  self.song_tag_d2v.wv.vectors], axis=0)\n","            self.tag_vectors = np.concatenate([np.zeros((2, self.vector_size)), \n","                                  self.tag_song_d2v.wv.vectors], axis=0)\n","            \n","            np.save(song_vectors_path, self.song_vectors)\n","            np.save(tag_vectors_path, self.tag_vectors)\n","            \n","        elif os.path.isfile(song_vectors_path) and os.path.isfile(tag_vectors_path):\n","            self.song_vectors = np.load(song_vectors_path)\n","            self.tag_vectors = np.load(tag_vectors_path)\n","\n","    def load_json(self, path):\n","        return json.load(open(path, 'r'))\n","    \n","    def get_d2v_models(self):\n","        song_tag_d2v_path = self.info_dir + 'song_tag_d2v.model'\n","        tag_song_d2v_path = self.info_dir + 'tag_song_d2v.model'\n","        \n","        song_tag_d2v = None\n","        tag_song_d2v = None\n","        if not(os.path.isfile(song_tag_d2v_path) and os.path.isfile(tag_song_d2v_path)):\n","            song_tag_doc_list = list()\n","            tag_song_doc_list = list()\n","            for plylst in chain(self.train_plylst_list, \n","                                self.val_plylst_list, \n","                                self.test_plylst_list):\n","                songs = list()\n","                for song in plylst['songs']:\n","                    songs.append(str(song))\n","                    \n","                tags = list()\n","                for tag in plylst['tags']:\n","                    tags.append(str(tag))\n","                    \n","                song_tag_doc_list.append(TaggedDocument(songs, tags))\n","                tag_song_doc_list.append(TaggedDocument(tags, songs))\n","\n","            song_tag_d2v = Doc2Vec(song_tag_doc_list, window=self.song_window, \n","                                   min_count=self.min_count, negative=self.negative, \n","                                   worker=self.worker, vector_size=self.vector_size)\n","            tag_song_d2v = Doc2Vec(tag_song_doc_list, window=self.tag_window, \n","                                   min_count=self.min_count, negative=self.negative, \n","                                   worker=self.worker, vector_size=self.vector_size)\n","            \n","            song_tag_d2v.save(song_tag_d2v_path)\n","            tag_song_d2v.save(tag_song_d2v_path)\n","\n","            \n","        elif os.path.isfile(song_tag_d2v_path) and os.path.isfile(tag_song_d2v_path):\n","            song_tag_d2v = Doc2Vec.load(song_tag_d2v_path)\n","            tag_song_d2v = Doc2Vec.load(tag_song_d2v_path)\n","        \n","        return song_tag_d2v, tag_song_d2v\n","    \n","    def get_maxlen(self):\n","        song_maxlen = -1\n","        tag_maxlen = -1\n","        for plylst in chain(self.train_plylst_list, \n","                            self.val_plylst_list, \n","                            self.test_plylst_list):\n","            song_maxlen = max(song_maxlen, len(plylst['songs']))\n","            tag_maxlen = max(tag_maxlen, len(plylst['tags']))\n","            \n","        return song_maxlen, tag_maxlen\n","    \n","    def generate_input(self, mode, batch_size):\n","        def _encode(plylst, feature):\n","            \n","            if feature == 'tag':\n","                feat_idxs = list()\n","                for tag in plylst['tags']:\n","                    if self.tag2idx.setdefault(str(tag), False):\n","                        feat_idxs.append(self.tag2idx[str(tag)])\n","                    else:\n","                        feat_idxs.append(self.tag2idx['<unk>'])\n","                feat_maxlen = self.tag_maxlen\n","                n_feats = self.n_tags\n","            else:\n","                feat_idxs = list()\n","                for song in plylst['songs']:\n","                    if self.song2idx.setdefault(str(song), False):\n","                        feat_idxs.append(self.song2idx[str(song)])\n","                    else:\n","                        feat_idxs.append(self.song2idx['<unk>'])\n","                feat_maxlen = self.song_maxlen\n","                n_feats = self.n_songs\n","\n","            # feat_included\n","            random.shuffle(feat_idxs)\n","            n_included = len(feat_idxs) // 2\n","            feat_included = feat_idxs[:n_included]\n","\n","            # feat_input: padded label encoding(feat_included)\n","            feat_input = np.zeros((feat_maxlen,), dtype=np.int32)\n","            feat_input[:n_included] = feat_included\n","\n","            # feat_label: one-hot encoding(feat_included & feat_excluded)\n","            feat_label = np.zeros((n_feats,), dtype=np.float64)\n","            feat_label[feat_idxs] = 1\n","            \n","            return feat_input, feat_label\n","        \n","        if mode == 'train':\n","            plylst_list = self.train_plylst_list\n","        elif mode == 'val':\n","            plylst_list = self.val_plylst_list\n","        elif mode == 'test':\n","            plylst_list = self.test_plylst_list\n","        else:\n","            raise(ValueError)\n","            \n","        song_input_list = list()\n","        tag_input_list = list()\n","        song_label_list = list()\n","        tag_label_list = list()\n","        for i, plylst in enumerate(plylst_list, 1):\n","            song_input, song_label = _encode(plylst, 'song')\n","            tag_input, tag_label = _encode(plylst, 'tag')\n","            song_input_list.append(song_input)\n","            tag_input_list.append(tag_input)\n","            song_label_list.append(song_label)\n","            tag_label_list.append(tag_label)\n","            \n","            if i%batch_size == 0:\n","                song_inputs = np.stack(song_input_list, axis=0)\n","                tag_inputs = np.stack(tag_input_list, axis=0)\n","                song_input_list = list()\n","                tag_input_list = list()\n","                \n","                song_labels = np.stack(song_label_list, axis=0)\n","                tag_labels = np.stack(tag_label_list, axis=0)\n","                song_label_list = list()\n","                tag_label_list = list()\n","                \n","                yield (song_inputs, tag_inputs), (song_labels, tag_labels)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"G6QNBgAyzPy2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":232},"executionInfo":{"status":"error","timestamp":1595426140012,"user_tz":-540,"elapsed":1109,"user":{"displayName":"Jaeho Jang","photoUrl":"","userId":"06755739837375243442"}},"outputId":"63b4914a-3b44-4548-a330-5d7928eee764"},"source":["import os\n","import sys\n","import random\n","\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","import tensorflow.keras as K\n","\n","# from .dataset import MPCDataset\n","\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","sys.path.append(\"/content/drive/My\\ Drive/MelonPlaylistContinuation\")\n","\n","\n","DATA_DIR = \"/content/drive/My\\ Drive/MelonPlaylistContinuation/data\"\n","INFO_DIR = \"/content/drive/My\\ Drive/MelonPlaylistContinuation/info\"\n","CKPT_DIR = \"/content/drive/My\\ Drive/MelonPlaylistContinuation/checkpoint/d2v_dense/\"\n","if not os.path.isdir(CKPT_DIR):\n","    os.mkdir(CKPT_DIR)\n","SEED = 200722\n","dataset = MPCDataset(DATA_DIR, INFO_DIR, vector_size=256)\n","\n","generator = iter(dataset.get_generator('train', batch_size=1))\n","song_plylst_vec_list = list()\n","tag_plylst_vec_list = list()\n","song_labels_list = list()\n","tag_labels_list = list()\n","\n","for step in range(N):\n","    (song_inputs, tag_inputs), (song_labels, tag_labels) = next(generator)\n","    song_nonzero = np.count_nonzero(song_inputs)\n","    tag_nonzero = np.count_nonzero(tag_inputs)\n","\n","    song_doc = [dataset.idx2song[song_idx] for song_idx in song_inputs[:song_nonzero]]\n","    tag_doc = [dataset.tag[tag_idx] for tag_idx in tag_inputs[:tag_nonzero]]\n","\n","    song_plylst_vec = dataset.song_tag_d2v.infer_vector(song_doc)\n","    song_plylst_vec_list.append(song_plylst_vec)\n","    tag_plylst_vec = dataset.tag_song_d2v.infer_vector(tag_doc)\n","    tag_plylst_vec_list.append(tag_plylst_vec)\n","\n","    song_labels_list.append(song_labels)\n","    tag_labels_list.append(tag_labels)\n","\n","X_song = np.stack(song_plylst_vec_list, axis=0)\n","X_song_train, X_song_val = train_test_split(X_song, test_size=0.3, random_state=SEED)\n","X_tag = np.stack(tag_plylst_vec_list, axis=0)\n","X_tag_train, X_tag_val = train_test_split(X_tag, test_size=0.3, random_state=SEED)\n","\n","y_song = np.stack(song_labels_list, axis=0)\n","y_song_train, y_song_val = train_test_split(y_song, test_size=0.3, random_state=SEED)\n","y_tag = np.stack(tag_labels_list, axis=0)\n","y_tag_train, y_tag_val = train_test_split(y_tag, test_size=0.3, random_state=SEED)\n","\n","# define model, opt\n","song_model = K.Sequential()\n","song_model.add(K.layers.Dense(128, input_shape=(256,)))\n","song_model.add(K.layers.Activation('relu'))\n","song_model.add(K.layers.Dense(64))\n","song_model.add(K.layers.Activation('relu'))\n","song_model.add(K.layers.Dense(dataset.n_songs))\n","song_opt = K.optimizers.Adam()\n","song_model.compile(optimizer=song_opt, loss=\"binary_crossentropy\")\n","\n","song_ckpt_path = os.path.join(CKPT_DIR, 'song', 'checkpoint')\n","song_model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=song_ckpt_path,\n","    save_weights_only=True,\n","    monitor='val_acc',\n","    mode='max',\n","    save_best_only=True)\n","\n","# train model\n","song_history = song_model.fit(\n","    X_song_train, y_song_train, \n","    batch_size=512, \n","    epochs=30, \n","    verbose=1,\n","    validation_data = (X_song_val, y_song_val),\n","    shuffle = True,\n","    callbacks = [song_model_checkpoint_callback]\n",")\n","\n","tag_model = K.Sequential()\n","tag_model.add(K.layers.Dense(128, input_shape=(256,)))\n","song_model.add(K.layers.Activation('relu'))\n","tag_model.add(K.layers.Dense(64))\n","song_model.add(K.layers.Activation('relu'))\n","tag_model.add(K.layers.Dense(dataset.n_tags))\n","tag_opt = K.optimizers.Adam()\n","tag_model.compile(optimizer=tag_opt, loss=\"binary_crossentropy\")\n","\n","tag_ckpt_path = os.path.join(CKPT_DIR, 'tag', 'checkpoint')\n","tag_model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=tag_ckpt_path,\n","    save_weights_only=True,\n","    monitor='val_acc',\n","    mode='max',\n","    save_best_only=True)\n","\n","# train model\n","tag_history = tag_model.fit(\n","    X_tag_train, y_tag_train, \n","    batch_size=512, \n","    epochs=30, \n","    verbose=1,\n","    validation_data = (X_tag_val, y_tag_val),\n","    shuffle = True,\n","    callbacks = [tag_model_checkpoint_callback]\n",")"],"execution_count":5,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-accd732a34dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mCKPT_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/My\\ Drive/MelonPlaylistContinuation/checkpoint/d2v_dense/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCKPT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCKPT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mSEED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200722\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMPCDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINFO_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My\\\\ Drive/MelonPlaylistContinuation/checkpoint/d2v_dense/'"]}]},{"cell_type":"code","metadata":{"id":"vHOAE8ctzW0s","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}